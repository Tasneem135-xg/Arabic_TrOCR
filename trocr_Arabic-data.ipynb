{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Credits goes to\n",
        "https://github.com/NielsRogge/Transformers-Tutorials/tree/master/TrOCR<br>\n",
        "https://arxiv.org/abs/2109.10282\n",
        "TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models\n",
        "<br>\n",
        "https://huggingface.co/aubmindlab/bert-base-arabert\n",
        "\n",
        "<br>\n",
        "https://huggingface.co/xlm-roberta-base\n"
      ],
      "metadata": {
        "id": "qRFz5Pbgz6eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torchvision\n",
        "!pip install \"accelerate>=0.20.1\"\n",
        "!pip install accelerate -U\n",
        "!pip install datasets\n",
        "!pip install jiwer\n"
      ],
      "metadata": {
        "id": "M4xe79qO4vme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries\n",
        "# Mount drive"
      ],
      "metadata": {
        "id": "G4CUOXvTXmBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4Km8DIBXh3f",
        "outputId": "003d14e5-def7-4fa4-bb74-eb8536a98082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#from scipy.sparse import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from transformers import TrOCRProcessor\n",
        "from transformers import AutoFeatureExtractor, AutoTokenizer\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from transformers import Trainer"
      ],
      "metadata": {
        "id": "oP6umDhXqDwZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "IJikGCu6XscV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = pd.read_csv(\"/content/drive/MyDrive/OCR_BLNK/OCR_DATA/unziped_data/clean_images.csv\",index_col=None)"
      ],
      "metadata": {
        "id": "_vHUmo-KYJne"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the \"imagename\" column to \"file name\"\n",
        "dff.rename(columns={'ImageName': 'file_name'}, inplace=True)\n",
        "dff.rename(columns={'TextContent': \"text\"}, inplace=True)\n",
        "# reduce the data size due to limited RAM and time\n",
        "df=dff.sample(n=2000, random_state=42)"
      ],
      "metadata": {
        "id": "eKMDwPpp3EII"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.3 ,random_state=42)\n",
        "# we reset the indices to start from zero\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "IqCCynUfqfwX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'textcontent' column to string\n",
        "train_df['text'] = train_df['text'].astype(str)\n",
        "# Calculate the length of words in the 'textcontent' column\n",
        "word_lengths = train_df['text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Plot a histogram\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.hist(word_lengths, bins=3, edgecolor='black')\n",
        "plt.title('Distribution of Word Lengths')\n",
        "plt.xlabel('Word Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# data consentrated around  9 to 13 tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "SK87jdwpw98e",
        "outputId": "17d6419a-02f2-41b6-a54a-7dec64b94b14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch data Class"
      ],
      "metadata": {
        "id": "AYEFf7mdy5R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max target legth = 20 to buffer for subword level tokenizer used by Transformers\n",
        "class IAMDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, df, processor, max_target_length=20):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get file name + text\n",
        "        file_name = self.df['file_name'][idx]\n",
        "        text = self.df['text'][idx]\n",
        "        # prepare image (i.e. resize + normalize)\n",
        "        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
        "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
        "        # add labels (input_ids) by encoding the text\n",
        "        labels = self.processor.tokenizer(text, padding=\"max_length\",max_length=self.max_target_length).input_ids[:self.max_target_length]\n",
        "        # important: make sure that PAD tokens are ignored by the loss function\n",
        "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
        "\n",
        "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
        "        return encoding"
      ],
      "metadata": {
        "id": "2pmM70QZx1za"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "gVPD_R5j6Jyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choosing feature extractor and tokenizer\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-384\")\n",
        "#decoder_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\")\n",
        "# using multilingual roberta fine tuned on arabic is better\n",
        "decoder_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "\n",
        "processor =TrOCRProcessor(feature_extractor=feature_extractor, tokenizer=decoder_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoAvt6Uk5mZ2",
        "outputId": "f46a7c7d-38af-48d2-814a-9f1622fe9950"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/trocr/processing_trocr.py:45: FutureWarning: The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor.save_pretrained('./processor')"
      ],
      "metadata": {
        "id": "GrwMlEBb21Jj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = TrOCRProcessor.from_pretrained(\"./processor\")\n",
        "datadir=\"/content/drive/MyDrive/OCR_BLNK/OCR_DATA/unziped_data/filtered_images/\"\n",
        "train_dataset = IAMDataset(root_dir=datadir ,df=train_df,processor=processor)\n",
        "eval_dataset = IAMDataset(root_dir= datadir ,df=test_df,processor=processor)"
      ],
      "metadata": {
        "id": "psYIuAEb5CKr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of training examples:\", len(train_dataset))\n",
        "print(\"Number of validation examples:\", len(eval_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uay3Urk-OBb",
        "outputId": "e1bcd352-4321-4e46-bc60-41981a998819"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 1400\n",
            "Number of validation examples: 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7kJ8pGaAFEC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = train_dataset[5]\n",
        "for k,v in encoding.items():\n",
        "    print(k, v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKreCqSr-TwY",
        "outputId": "1b3f7e0c-dfcb-49c9-b57a-e9940a6ead4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel_values torch.Size([3, 384, 384])\n",
            "labels torch.Size([20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(train_dataset.root_dir + train_df['file_name'][5]).convert(\"RGB\")\n",
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "WUgJw6TA-2k0",
        "outputId": "03f185f8-94ee-46a8-d190-0f568d5181fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=500x80>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = encoding['labels']\n",
        "labels[labels == -100] = processor.tokenizer.pad_token_id\n",
        "label_str = processor.decode(labels, skip_special_tokens=True)\n",
        "print(label_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1LsAuIeAUK1",
        "outputId": "d75339a3-523e-4b32-f96d-ba8fded4e98b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "355 شارع ديري متفرع من سبروتبورو في ١٧١٠ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel\n",
        "\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"google/vit-base-patch16-384\", 'xlm-roberta-base')\n",
        "# set decoder config to causal lm\n",
        "model.config.decoder.is_decoder = True\n",
        "model.config.decoder.add_cross_attention = True\n",
        "# set special tokens used for creating the decoder_input_ids from the labels\n",
        "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "# make sure vocab size is set correctly\n",
        "model.config.vocab_size = model.config.decoder.vocab_size\n",
        "\n",
        "# set beam search parameters\n",
        "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
        "# make max_length = 20\n",
        "model.config.max_length = 20\n",
        "model.config.early_stopping = True\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.num_beams = 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSUPJRYqAhem",
        "outputId": "4b9f46c1-f898-4ceb-e986-2b81d9c183fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-384 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForCausalLM were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_bIEYsbC-8Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the training arguments for the Seq2SeqTrainer\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,  # Enable generation mode during evaluation\n",
        "    evaluation_strategy=\"epoch\",  # Strategy for when to evaluate the model during training\n",
        "    per_device_train_batch_size=3,  # Batch size for training data (per device)\n",
        "    per_device_eval_batch_size=3,   # Batch size for evaluation data (per device)\n",
        "    fp16= False,  # Enable mixed-precision training for faster training on supported GPUs\n",
        "    output_dir=\"/content/drive/MyDrive/OCR_BLNK/OCR_DATA/unziped_data\",  # Directory to save checkpoints and logs\n",
        "    logging_steps=2,  # Log metrics every specified number of training steps\n",
        "    save_steps=20,  # Save model checkpoint every specified number of steps\n",
        "    eval_steps=200,   # Evaluate model every specified number of steps during training\n",
        "    num_train_epochs=3,  # Total number of training epochs\n",
        "    )\n"
      ],
      "metadata": {
        "id": "3vZzfO5nCS1o"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rbrRJpnzNOG-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "cer_metric = load_metric(\"cer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFeSjR1dG_tp",
        "outputId": "2ef8a580-f6d7-4875-89ce-327a83bfc567"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-6424484073b5>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  cer_metric = load_metric(\"cer\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"cer\": cer}"
      ],
      "metadata": {
        "id": "NPFQr228G_3P"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load the checkpointed model\n",
        "model = VisionEncoderDecoderModel.from_pretrained('/content/drive/MyDrive/OCR_BLNK/OCR_DATA/unziped_data/checkpoint-520')\n",
        "\n",
        "\n",
        "\n",
        "from transformers import default_data_collator\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    #tokenizer=processor.image_processor,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=default_data_collator\n",
        ")\n",
        "trainer.train(resume_from_checkpoint=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "PuSqpoMqHmw9",
        "outputId": "32765ec4-569c-4b76-9543-0f6f70edbdc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/trocr/processing_trocr.py:135: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='602' max='1401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 602/1401 50:55 < 8:28:41, 0.03 it/s, Epoch 1.29/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='627' max='1401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 627/1401 1:05:29 < 8:02:45, 0.03 it/s, Epoch 1.34/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('/content/drive/MyDrive/OCR_BLNK/OCR_DATA/unziped_data/trainer')"
      ],
      "metadata": {
        "id": "Pw7gIFdKHrC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VisionEncoderDecoderModel.from_pretrained('/content/drive/MyDrive/OCR_BLNK/OCR_DATA/unziped_data/trainer')"
      ],
      "metadata": {
        "id": "4kxemgy_Ondo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(\"/content/drive/MyDrive/OCR_BLNK/OCR_DATA/samples_images/0.jpg\").convert(\"RGB\")\n",
        "\n",
        "pixel_values = processor.feature_extractor(image, return_tensors=\"pt\").pixel_values\n",
        "print(pixel_values.shape)\n",
        "\n",
        "generated_ids = model.generate(pixel_values)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "qdcTjF2COusi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/OCR_BLNK/OCR_DATA/unziped_data/trainer')"
      ],
      "metadata": {
        "id": "LIVI_Mx0D_yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to ONNX"
      ],
      "metadata": {
        "id": "PkdUg_SQ_MPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import VisionEncoderDecoderModel\n",
        "from transformers import AutoFeatureExtractor, AutoProcessor\n",
        "\n",
        "# Load the checkpointed model\n",
        "model = VisionEncoderDecoderModel.from_pretrained('/content/drive/MyDrive/OCR_BLNK/OCR_DATA/unziped_data/trainer')\n",
        "\n",
        "\n",
        "# Load the feature extractor and processor\n",
        "feature_extractor = = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-384\")\n",
        "decoder_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "processor =TrOCRProcessor(feature_extractor=feature_extractor, tokenizer=decoder_tokenizer)\n",
        "# Create dummy input\n",
        "batch_size = 3  # Replace with your batch size\n",
        "channels = 3    # Replace with the number of image channels (e.g., 3 for RGB)\n",
        "height = 384    # Replace with your image height\n",
        "width = 384     # Replace with your image width\n",
        "max_seq_length = 20  # Replace with your maximum sequence length\n",
        "\n",
        "dummy_image_input = torch.randn(batch_size, channels, height, width)\n",
        "dummy_text_input = torch.randint(0, processor.tokenizer.vocab_size, (batch_size, max_seq_length))\n",
        "\n",
        "# Run the model's forward pass (without training)\n",
        "with torch.no_grad():\n",
        "    outputs = model(pixel_values=dummy_image_input, input_ids=dummy_text_input)\n",
        "\n",
        "# Export the core model to ONNX\n",
        "onnx_path = \"path_to_save/model.onnx\"  # Replace with your desired path\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    (dummy_image_input, dummy_text_input),\n",
        "    onnx_path,\n",
        "    verbose=True,\n",
        "    input_names=[\"pixel_values\", \"input_ids\"],\n",
        "    output_names=[\"logits\"],\n",
        ")\n",
        "\n",
        "print(\"Model exported to ONNX:\", onnx_path)\n"
      ],
      "metadata": {
        "id": "pZdd_auOa5Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to TRT"
      ],
      "metadata": {
        "id": "v6PZiP8jMER5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt as trt\n",
        "\n",
        "# Initialize TensorRT\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
        "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_path = 'model.onnx'\n",
        "onnx_model = onnx.load(onnx_path)\n",
        "\n",
        "# Create a TensorRT builder and network\n",
        "builder = trt.Builder(TRT_LOGGER)\n",
        "network = builder.create_network()\n",
        "\n",
        "# Parse the ONNX model into the TensorRT network\n",
        "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "success = parser.parse(onnx_model.SerializeToString())\n",
        "\n",
        "# Build an optimized TensorRT engine\n",
        "engine = builder.build_cuda_engine(network)\n",
        "\n",
        "# Save the TensorRT engine\n",
        "trt_path = 'model_trt.engine'\n",
        "with open(trt_path, 'wb') as f:\n",
        "    f.write(engine.serialize())\n"
      ],
      "metadata": {
        "id": "QqHD_jqoMHZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}